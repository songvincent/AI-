{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\as\\miniconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s',level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sentences = [\"the quick brown fox jumps over the lazy dogs\",\"yoyoyo you go home now to sleep\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences= [s.split() for s in raw_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dogs'], ['yoyoyo', 'you', 'go', 'home', 'now', 'to', 'sleep']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-01 20:53:25,008: INFO: collecting all words and their counts\n",
      "2018-02-01 20:53:25,011: INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-02-01 20:53:25,014: INFO: collected 15 word types from a corpus of 16 raw words and 2 sentences\n",
      "2018-02-01 20:53:25,016: INFO: Loading a fresh vocabulary\n",
      "2018-02-01 20:53:25,019: INFO: min_count=1 retains 15 unique words (100% of original 15, drops 0)\n",
      "2018-02-01 20:53:25,021: INFO: min_count=1 leaves 16 word corpus (100% of original 16, drops 0)\n",
      "2018-02-01 20:53:25,024: INFO: deleting the raw counts dictionary of 15 items\n",
      "2018-02-01 20:53:25,027: INFO: sample=0.001 downsamples 15 most-common words\n",
      "2018-02-01 20:53:25,029: INFO: downsampling leaves estimated 2 word corpus (13.7% of prior 16)\n",
      "2018-02-01 20:53:25,033: INFO: estimated required memory for 15 words and 100 dimensions: 19500 bytes\n",
      "2018-02-01 20:53:25,130: INFO: resetting layer weights\n",
      "2018-02-01 20:53:25,145: INFO: training model with 3 workers on 15 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-02-01 20:53:25,176: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-02-01 20:53:25,180: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-02-01 20:53:25,207: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-02-01 20:53:25,210: INFO: training on 80 raw words (12 effective words) took 0.0s, 348 effective words/s\n",
      "2018-02-01 20:53:25,217: WARNING: under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\as\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.12697975412416782"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('dogs','fox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>外部语料集</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-01 22:02:37,282: INFO: collecting all words and their counts\n",
      "2018-02-01 22:02:37,285: INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-02-01 22:02:37,288: INFO: collected 15 word types from a corpus of 16 raw words and 2 sentences\n",
      "2018-02-01 22:02:37,290: INFO: Loading a fresh vocabulary\n",
      "2018-02-01 22:02:37,293: INFO: min_count=5 retains 0 unique words (0% of original 15, drops 15)\n",
      "2018-02-01 22:02:37,296: INFO: min_count=5 leaves 0 word corpus (0% of original 16, drops 16)\n",
      "2018-02-01 22:02:37,299: INFO: deleting the raw counts dictionary of 15 items\n",
      "2018-02-01 22:02:37,301: INFO: sample=0.001 downsamples 0 most-common words\n",
      "2018-02-01 22:02:37,303: INFO: downsampling leaves estimated 0 word corpus (0.0% of prior 0)\n",
      "2018-02-01 22:02:37,306: INFO: estimated required memory for 0 words and 100 dimensions: 0 bytes\n",
      "2018-02-01 22:02:37,309: INFO: Loading a fresh vocabulary\n",
      "2018-02-01 22:02:37,312: INFO: min_count=5 retains 0 unique words (0% of original 0, drops 0)\n",
      "2018-02-01 22:02:37,314: INFO: min_count=5 leaves 0 word corpus (0% of original 0, drops 0)\n",
      "2018-02-01 22:02:37,315: INFO: deleting the raw counts dictionary of 0 items\n",
      "2018-02-01 22:02:37,317: INFO: sample=0.001 downsamples 0 most-common words\n",
      "2018-02-01 22:02:37,319: INFO: downsampling leaves estimated 0 word corpus (0.0% of prior 0)\n",
      "2018-02-01 22:02:37,321: INFO: estimated required memory for 0 words and 100 dimensions: 0 bytes\n",
      "2018-02-01 22:02:37,323: INFO: resetting layer weights\n",
      "2018-02-01 22:02:37,325: INFO: training model with 3 workers on 0 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "you must first build vocabulary before training the model",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-9ce21213e758>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMySentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# a memory-friendly iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\as\\miniconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss)\u001b[0m\n\u001b[0;32m    552\u001b[0m             self.train(\n\u001b[0;32m    553\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m                 \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m             )\n\u001b[0;32m    556\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\as\\miniconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sentences, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss)\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"you must first build vocabulary before training the model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"you must first finalize vocabulary before training the model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: you must first build vocabulary before training the model"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# from gensim import models\n",
    "# class MySentences(object):\n",
    "#     def __init__(self, dirname):\n",
    "#         self.dirname = dirname\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         for fname in os.listdir(self.dirname):\n",
    "#             for line in open(os.path.join(self.dirname, fname)):\n",
    "# #                 yield line.split()\n",
    "\n",
    "# sentences = MySentences('./data') # a memory-friendly iterator\n",
    "# model2 = models.Word2Vec(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MySentences(object):\n",
    "#     def __init__(self,dirname):\n",
    "#         self.dirname=dirname\n",
    "        \n",
    "#     def __iter__self():\n",
    "#         with open(dirname,encoding='utf-8') as f1:\n",
    "#             l=[]\n",
    "#             for line1 in f1.readlines():\n",
    "#                 yield line1.split()\n",
    "#         f1.close()\n",
    "#         print(l)\n",
    "#         return l;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the quick brown fox jumps over the lazy dogs', 'yoyoyo you go home now to sleep']\n"
     ]
    }
   ],
   "source": [
    "with open(\"data.txt\",encoding='utf-8') as f:\n",
    "    lines=f.readlines()\n",
    "f.close()\n",
    "\n",
    "rawsentences=[]\n",
    "for line in lines:\n",
    "    rawsentences.append(line.strip())\n",
    "print(rawsentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>模型保存与加载</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-01 22:15:31,951: INFO: saving Word2Vec object under model, separately None\n",
      "2018-02-01 22:15:31,953: INFO: not storing attribute syn0norm\n",
      "2018-02-01 22:15:31,956: INFO: not storing attribute cum_table\n",
      "2018-02-01 22:15:31,967: INFO: saved model\n"
     ]
    }
   ],
   "source": [
    "model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-01 22:16:27,913: INFO: loading Word2Vec object from model\n",
      "2018-02-01 22:16:27,916: INFO: loading wv recursively from model.wv.* with mmap=None\n",
      "2018-02-01 22:16:27,918: INFO: setting ignored attribute syn0norm to None\n",
      "2018-02-01 22:16:27,919: INFO: setting ignored attribute cum_table to None\n",
      "2018-02-01 22:16:27,921: INFO: loaded model\n"
     ]
    }
   ],
   "source": [
    "model1 = models.Word2Vec.load('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\as\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.12697975412416782"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.similarity('dogs','fox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>模型预测</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\as\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -1.43371639e-03,   3.39592603e-04,  -4.82715853e-03,\n",
       "        -1.06500415e-03,   1.06490985e-03,  -2.30263826e-03,\n",
       "         3.11306491e-03,   3.93575709e-03,   2.38170964e-03,\n",
       "         3.75716900e-03,  -4.74439887e-03,   4.70637670e-03,\n",
       "         2.11448711e-03,  -4.48235590e-03,  -1.87792198e-03,\n",
       "         1.69350184e-03,  -3.87568376e-03,   4.35113441e-03,\n",
       "         1.17080018e-03,   1.52961549e-03,   3.72253568e-03,\n",
       "         6.07641821e-04,   1.31964695e-03,  -4.21514548e-03,\n",
       "         4.80567990e-03,  -3.33887467e-04,   4.16353112e-03,\n",
       "         4.19910904e-03,  -6.09879324e-04,   3.90721438e-03,\n",
       "         4.07856470e-03,  -4.85367287e-04,   2.02448783e-03,\n",
       "        -4.01668716e-03,  -4.34152782e-03,  -3.58902547e-03,\n",
       "         3.91176436e-03,  -9.42448271e-04,   3.95113043e-03,\n",
       "         2.12934287e-03,  -3.63369100e-03,  -7.71737425e-04,\n",
       "        -1.63726602e-03,  -2.73962202e-03,   9.54843825e-04,\n",
       "        -4.83996794e-03,  -9.46383807e-05,  -1.02703983e-03,\n",
       "         1.11635204e-03,  -4.28281398e-03,   2.66982615e-03,\n",
       "        -3.75294080e-03,  -2.63146171e-03,  -2.94501055e-03,\n",
       "         3.88933322e-03,   3.17435665e-03,   4.55507822e-03,\n",
       "         1.87025697e-03,   7.22246070e-04,   2.17584497e-03,\n",
       "        -2.36633176e-04,   1.57130684e-03,   4.19165567e-03,\n",
       "         1.25024561e-03,  -2.20306590e-03,   3.06774187e-03,\n",
       "         3.04443849e-04,   1.75716262e-03,  -2.13009701e-03,\n",
       "        -4.34132945e-03,   1.89246517e-03,  -3.26731452e-03,\n",
       "        -4.37310338e-03,  -2.63204391e-04,  -7.59401184e-04,\n",
       "        -4.92228894e-03,   1.37932587e-03,   1.29182602e-03,\n",
       "        -4.19791118e-04,  -3.48275551e-03,   6.55529904e-04,\n",
       "        -4.85934550e-03,  -1.15852687e-03,  -2.17936956e-03,\n",
       "        -3.16671445e-04,   3.91726289e-03,   2.50530080e-03,\n",
       "        -3.84213193e-03,  -4.71581332e-03,   3.52786435e-03,\n",
       "        -1.36126400e-04,   3.41224065e-03,  -9.49232664e-04,\n",
       "        -4.05299012e-03,  -4.80250252e-04,  -3.75222485e-03,\n",
       "        -2.61247228e-03,  -4.80300328e-03,   2.80196196e-03,\n",
       "         1.70432191e-04], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将词转化为向量\n",
    "model1['dogs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\as\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "2018-02-01 22:22:04,339: INFO: precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('yoyoyo', 0.13620921969413757)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#预测出最近似的词语\n",
    "model.most_similar(positive=['you'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\as\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dogs'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#找出不匹配的词语\n",
    "model.doesnt_match(\"dogs you sleep\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\as\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('yoyoyo', 0.13620921969413757),\n",
       " ('the', 0.08452343940734863),\n",
       " ('sleep', 0.059690337628126144),\n",
       " ('fox', 0.043551817536354065),\n",
       " ('over', 0.02083089016377926),\n",
       " ('brown', 0.005292321555316448),\n",
       " ('home', -0.011036878451704979),\n",
       " ('go', -0.06855002045631409),\n",
       " ('dogs', -0.0886785089969635),\n",
       " ('to', -0.14406436681747437)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#最相似的词语\n",
    "model.most_similar(['you'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "missing section header before line #0 in ./data.txt",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-f44caacff018>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\as\\miniconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(self, questions, restrict_vocab, most_similar, case_insensitive)\u001b[0m\n\u001b[0;32m   1508\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmost_similar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase_insensitive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1509\u001b[0m         \u001b[0mmost_similar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmost_similar\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1510\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmost_similar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase_insensitive\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1512\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\as\\miniconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(self, questions, restrict_vocab, most_similar, case_insensitive)\u001b[0m\n\u001b[0;32m    901\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msection\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"missing section header before line #%i in %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline_no\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mcase_insensitive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: missing section header before line #0 in ./data.txt"
     ]
    }
   ],
   "source": [
    "model.accuracy('./data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
